{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "def f(x: float):\n",
    "    b = 1000.0\n",
    "    c = 2000.0\n",
    "    return (x - b) * (x - c)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "def f_grad(funct, arg:float):\n",
    "    eps = 0.000001\n",
    "    return (funct(arg) - funct(arg - eps)) / eps"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "def sgd_fixed_learning_rate(funct, lr: float = 1e-1, diff_limit: float = 1e-8):\n",
    "    eval_f = 1\n",
    "    eval_gf = 0\n",
    "    optimum = 0\n",
    "    prev_value = funct(optimum)\n",
    "    diff_value = 1000000.0\n",
    "    while diff_value > diff_limit:\n",
    "        optimum -= lr * f_grad(funct, optimum)\n",
    "        new_value = funct(optimum)\n",
    "        eval_f += 1\n",
    "        eval_gf += 1\n",
    "        diff_value = abs(new_value - prev_value)\n",
    "        prev_value = new_value\n",
    "    return optimum, eval_f, eval_gf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "def sgd_fixed_learning_rate_table(f, lr_vector, diff_limit_vector):\n",
    "    res =  \"| lr | dl | opt | f | grad |\\n\"\n",
    "    res += \"| --- | ---- | --- | --- | --- |\\n\"\n",
    "    for diff_limit in diff_limit_vector:\n",
    "        for lr in lr_vector:\n",
    "            r = sgd_fixed_learning_rate(f, lr, diff_limit)\n",
    "            res += f'| {lr} | {diff_limit} | {r[0]} | {r[1]} | {r[2]} |\\n'\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(sgd_fixed_learning_rate_table(f, [1e-1, 1e-2, 1e-3, 1e-4], [1e-5, 1e-8]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| lr | dl | opt | f | grad |\n",
      "| --- | ---- | --- | --- | --- |\n",
      "| 0.1 | 1e-05 | 1499.9964076196193 | 59 | 58 |\n",
      "| 0.01 | 1e-05 | 1499.984734332429 | 570 | 569 |\n",
      "| 0.001 | 1e-05 | 1499.9501680827905 | 5152 | 5151 |\n",
      "| 0.0001 | 1e-05 | 1499.8419272332521 | 45786 | 45785 |\n",
      "| 0.1 | 1e-08 | 1499.9998738858267 | 74 | 73 |\n",
      "| 0.01 | 1e-08 | 1499.9995184962245 | 741 | 740 |\n",
      "| 0.001 | 1e-08 | 1499.9984272686504 | 6878 | 6877 |\n",
      "| 0.0001 | 1e-08 | 1499.9949992311722 | 63051 | 63050 |\n",
      "\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}